{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is test file for a new repository\n"
     ]
    }
   ],
   "source": [
    "print('this is test file for a new repository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine('')\n",
    "\n",
    "\n",
    "# определяем функцию получения данных из первичного источника\n",
    "# она получает на вход объект соединения к первичному источнику\n",
    "# и возвращает данные из всех таблиц, собранные в одном pandas.DataFrame\n",
    "def extract(cnx) -> pd.DataFrame:\n",
    "  # сначала напишите SQL-запрос, который объединяет все таблицы в одну\n",
    "\tsql_query = '''SELECT contracts.customer_id, begin_date, end_date, type,\n",
    "    paperless_billing, payment_method, monthly_charges,\n",
    "    total_charges,internet_service,online_security,\n",
    "    online_backup,device_protection,tech_support,streaming_tv,\n",
    "    streaming_movies,gender,senior_citizen,partner,\n",
    "    dependents,multiple_lines FROM contracts\n",
    "    Left join internet on internet.customer_id = contracts.customer_id \n",
    "    Left join personal on personal.customer_id = contracts.customer_id\n",
    "    Left join phone on phone.customer_id = contracts.customer_id'''\n",
    "\tdata = pd.read_sql(sql_query, cnx) #исполним написанный запрос\n",
    "\treturn data\n",
    "    \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data['end_date'] = data['end_date'].replace('No', None)\n",
    "    data['target'] = pd.notnull(data['end_date'])\n",
    "    data['target'] = data['target'].astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_engine('')\n",
    "\n",
    "def load(data: pd.DataFrame, db_conn: sqlalchemy.engine.base.Engine, table_name: str = 'users_churn'):\n",
    "    data.to_sql(name=table_name, con=db_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.decorators import task\n",
    "# ваш код здесь\n",
    "@task()\n",
    "def load(data: pd.DataFrame):\n",
    "    hook = PostgresHook('destination_db')\n",
    "    conn = hook.get_conn()\n",
    "    hook.insert_rows(\n",
    "            table=\"users_churn\",\n",
    "            replace=True,\n",
    "            target_fields=data.columns.tolist(),\n",
    "            replace_index=['customer_id'],\n",
    "            rows=data.values.tolist()\n",
    "    )\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.decorators import task, dag\n",
    "from pendulum import datetime\n",
    "# ваш код здесь\n",
    "@dag(schedule='@once',start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),tags=[\"churn\"]) # обозначаем, что это DAG, и определяем параметры\n",
    "def prepare_churn_dataset():\n",
    "    # ваш код здесь\n",
    "    @task() #extract\n",
    "    def extract() -> pd.DataFrame:\n",
    "        hook = PostgresHook('source_db')\n",
    "        conn = hook.get_conn()\n",
    "        sql_query = f\"\"\"\n",
    "            select\n",
    "                c.customer_id, c.begin_date, c.end_date, c.type, c.paperless_billing, c.payment_method, c.monthly_charges, c.total_charges,\n",
    "                i.internet_service, i.online_security, i.online_backup, i.device_protection, i.tech_support, i.streaming_tv, i.streaming_movies,\n",
    "                p.gender, p.senior_citizen, p.partner, p.dependents,\n",
    "                ph.multiple_lines\n",
    "            from contracts as c\n",
    "            left join internet as i on i.customer_id = c.customer_id\n",
    "            left join personal as p on p.customer_id = c.customer_id\n",
    "            left join phone as ph on ph.customer_id = c.customer_id\n",
    "            \"\"\"\n",
    "        data = pd.read_sql(sql_query, conn) #исполним написанный запрос\n",
    "        hook.close()\n",
    "        return data\n",
    "\n",
    "    @task() #transform\n",
    "    def transform(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        data['target'] = (data['end_date'] != 'No').astype(int)\n",
    "        data['end_date'].replace({'No': None}, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    @task() #load\n",
    "    def load(data: pd.DataFrame):\n",
    "        hook = PostgresHook('destination_db')\n",
    "        conn = hook.get_conn()\n",
    "        hook.insert_rows(\n",
    "            table=\"users_churn\",\n",
    "            replace=True,\n",
    "            target_fields=data.columns.tolist(),\n",
    "            replace_index=['customer_id'],\n",
    "            rows=data.values.tolist()\n",
    "        )\n",
    "        conn.close()\n",
    "    data = extract()\n",
    "    transformed_data = transform(data)\n",
    "    load(transformed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
